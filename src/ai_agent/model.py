import time
from abc import ABC, abstractmethod
from typing import Any, Dict, List

import openai

from .logger import get_logger
from .performance import PerformanceTracker


def estimate_tokens(text: str) -> int:
    """Estimate token count for text (approx 4 chars per token)."""
    """ä¼°ç®—æ–‡æœ¬çš„Tokenæ•°é‡ï¼ˆå¤§çº¦4ä¸ªå­—ç¬¦1ä¸ªTokenï¼‰"""
    return max(1, len(text) // 4)


logger = get_logger(__name__)


class AIClient(ABC):
    """Abstract base class for AI model clients."""

    """AIæ¨¡å‹å®¢æˆ·ç«¯çš„æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def complete(self, prompt: str, **kwargs) -> str:
        """Generate completion for the given prompt."""
        """ä¸ºç»™å®šçš„æç¤ºç”Ÿæˆè¡¥å…¨å†…å®¹"""
        pass

    @abstractmethod
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """Generate chat completion for the given messages."""
        """ä¸ºç»™å®šçš„æ¶ˆæ¯ç”ŸæˆèŠå¤©è¡¥å…¨å†…å®¹"""
        pass

    @abstractmethod
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics including token usage and costs."""
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬Tokenä½¿ç”¨æƒ…å†µå’Œæˆæœ¬"""
        pass

    @abstractmethod
    def reset_performance_stats(self):
        """Reset performance tracking statistics."""
        """é‡ç½®æ€§èƒ½è·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯"""
        pass


class OpenAIClient(AIClient):
    """OpenAI API client implementation."""

    """OpenAI APIå®¢æˆ·ç«¯å®ç°"""

    def __init__(self, api_key: str, model: str = "gpt-4", **kwargs):
        # Extract base_url from kwargs if provided
        # ä»kwargsä¸­æå–base_urlï¼ˆå¦‚æœæä¾›ï¼‰
        base_url = kwargs.pop("base_url", None)

        logger.info(f"Initializing OpenAI client with model: {model}")

        # Create OpenAI client with optional base_url
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œæ”¯æŒå¯é€‰çš„base_url
        client_kwargs = {"api_key": api_key}
        if base_url:
            client_kwargs["base_url"] = base_url
            logger.debug(f"Using custom base URL: {base_url}")

        self.client = openai.OpenAI(**client_kwargs)
        self.model = model
        self.default_params = {"temperature": 0.7, "max_tokens": 2000, **kwargs}
        self.performance_tracker = PerformanceTracker()
        logger.debug(f"Default parameters: {self.default_params}")

    def complete(self, prompt: str, **kwargs) -> str:
        params = {**self.default_params, **kwargs}
        logger.debug(
            f"Sending completion request to {self.model}, prompt length: {len(prompt)}"
        )

        start_time = time.time()

        try:
            response = self.client.completions.create(
                model=self.model, prompt=prompt, **params
            )

            duration_ms = (time.time() - start_time) * 1000

            # Record API call with token usage
            self.performance_tracker.record_api_call(
                provider="openai",
                model=self.model,
                endpoint="completions",
                prompt_tokens=response.usage.prompt_tokens,
                completion_tokens=response.usage.completion_tokens,
                duration_ms=duration_ms,
            )

            logger.debug(
                f"Completion response received, tokens: {response.usage.total_tokens}, "
                f"duration: {duration_ms:.2f}ms"
            )

            # Log the raw response content for debugging
            raw_text = response.choices[0].text
            logger.debug(f"ğŸ“ [MODEL RAW OUTPUT] Raw model response: {raw_text}")

            return raw_text.strip()

        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000

            # Record failed API call
            self.performance_tracker.record_api_call(
                provider="openai",
                model=self.model,
                endpoint="completions",
                prompt_tokens=0,
                completion_tokens=0,
                duration_ms=duration_ms,
                success=False,
                error_message=str(e),
            )

            logger.error(f"Completion request failed: {str(e)}")
            raise

    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        params = {**self.default_params, **kwargs}
        logger.debug(f"Sending chat request to {self.model}, messages: {len(messages)}")

        start_time = time.time()

        try:
            response = self.client.chat.completions.create(
                model=self.model, messages=messages, **params
            )

            duration_ms = (time.time() - start_time) * 1000

            # Record API call with token usage
            self.performance_tracker.record_api_call(
                provider="openai",
                model=self.model,
                endpoint="chat/completions",
                prompt_tokens=response.usage.prompt_tokens,
                completion_tokens=response.usage.completion_tokens,
                duration_ms=duration_ms,
            )

            logger.debug(
                f"Chat response received, tokens: {response.usage.total_tokens}, "
                f"duration: {duration_ms:.2f}ms"
            )

            # Log the raw response content for debugging
            raw_content = response.choices[0].message.content
            logger.debug(f"ğŸ“ [MODEL RAW OUTPUT] Raw model response: {raw_content}")

            return raw_content.strip()

        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000

            # Record failed API call
            self.performance_tracker.record_api_call(
                provider="openai",
                model=self.model,
                endpoint="chat/completions",
                prompt_tokens=0,
                completion_tokens=0,
                duration_ms=duration_ms,
                success=False,
                error_message=str(e),
            )

            logger.error(f"Chat request failed: {str(e)}")
            raise

    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics including token usage and costs."""
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬Tokenä½¿ç”¨æƒ…å†µå’Œæˆæœ¬"""
        return self.performance_tracker.get_statistics()

    def reset_performance_stats(self):
        """Reset performance tracking statistics."""
        """é‡ç½®æ€§èƒ½è·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯"""
        self.performance_tracker.reset()


def create_client(config: Dict[str, Any]) -> AIClient:
    """Factory function to create appropriate AI client based on config."""
    """æ ¹æ®é…ç½®åˆ›å»ºé€‚å½“çš„AIå®¢æˆ·ç«¯çš„å·¥å‚å‡½æ•°"""
    provider = config.get("provider", "openai")
    logger.info(f"Creating AI client for provider: {provider}")

    if provider == "openai":
        logger.debug("Creating OpenAI client - åˆ›å»ºOpenAIå®¢æˆ·ç«¯")
        return OpenAIClient(
            api_key=config["api_key"],
            model=config.get("model", "deepseek-chat"),
            temperature=config.get("temperature", 0.7),
            max_tokens=config.get("max_tokens", 2000),
            base_url=config.get("base_url"),
        )
    else:
        logger.error(f"Unsupported AI provider: {provider}")
        raise ValueError(f"Unsupported AI provider: {provider}")
